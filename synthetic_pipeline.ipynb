{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from random import shuffle, randint, choice\n",
    "from collections import Counter\n",
    "from utils import HOMEPATH\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translating(langsents, lang):\n",
    "    '''Translator function'''\n",
    "    step = 30\n",
    "    sents = []\n",
    "    interval = len(langsents) // step + 1\n",
    "    f = IntProgress(description=f'{lang}:', min=1, max=interval + 1, style= {'description_width': 'initial'})\n",
    "    display(f)\n",
    "\n",
    "    for i in range(interval):\n",
    "        if (i + 1) * step < len(langsents):\n",
    "            text = '\\n'.join(langsents[i * step:(i + 1) * step])\n",
    "        else:\n",
    "            text = '\\n'.join(langsents[i * step:])\n",
    "            if not text:\n",
    "                break\n",
    "        sent = translator.translate(text, src='en', dest=lang).text\n",
    "        sents.extend(sent.split('\\n'))\n",
    "        time.sleep(randint(9, 30))\n",
    "        f.value += 1\n",
    "    return sents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writesents(sents, lang, category):\n",
    "    '''Recording sents'''\n",
    "    with open(f'{HOMEPATH}{category}_{lang}_sents.json', 'w', encoding='utf8') as file:\n",
    "        json.dump(sents, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadsents(lang, category):\n",
    "    '''Reading sents'''\n",
    "    with open(f'{HOMEPATH}{category}_{lang}_sents.json',  encoding='utf8') as file:\n",
    "        return json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentmerger(cleansents):\n",
    "    '''Merge sentences before translating'''\n",
    "    res = []\n",
    "    for sent in cleansents:\n",
    "        string = ''\n",
    "        for token in sent:\n",
    "            if string and re.match(r'(?i)[\\[\\]<>a-z0-9-]+|<\\$%\\|', token[0]):\n",
    "                string += ' '\n",
    "            string += token[0]\n",
    "        string = string.replace('  ', ' ')\n",
    "        res.append(string)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_translate(source, category):\n",
    "    dataset = [source]\n",
    "    for language in ['ru', 'pl', 'be', 'uk', 'bg', 'sl', 'cs']:\n",
    "        resultsents = None\n",
    "        while not resultsents:\n",
    "            try:\n",
    "                resultsents = translating(source, language)\n",
    "            except:\n",
    "                print('Connection time out. Retry...')\n",
    "                time.sleep(5)\n",
    "        writesents(resultsents, language, category)\n",
    "        dataset.append(resultsents)\n",
    "    df = pd.DataFrame(zip(*dataset), columns=['en', 'ru', 'pl', 'be', 'uk', 'bg', 'sl', 'cs'])\n",
    "    df.to_csv(f'{HOMEPATH}{category}_{len(df)}sents.csv', index=False)\n",
    "    pickle.dump(df, open(f'{HOMEPATH}{category}_{len(df)}sents', 'wb'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Download and prepare WikiNERen'''\n",
    "with open(f'{HOMEPATH}aij-wikiner-en-wp2', encoding='utf8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = [t.split('|') for t in data[i].strip().split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero version (straight translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "'''Version B1 sents'''\n",
    "num = 0\n",
    "cleansents = []\n",
    "dct = {'I-PER': 0, 'I-LOC': 1, 'I-ORG': 2}\n",
    "for i in range(len(data)):\n",
    "    if num >= 10000:\n",
    "        break\n",
    "    labels = set((t[2] for t in data[i]))\n",
    "    if labels.issubset({'I-PER', 'I-LOC', 'I-ORG', 'O'}):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j][2] in {'I-PER', 'I-LOC', 'I-ORG'}:\n",
    "                data[i][j][0] = f'{data[i][j][0]} |{dct[data[i][j][2]]}|'\n",
    "        cleansents.append(data[i])\n",
    "        num += 1\n",
    "\n",
    "print(len(cleansents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerosents = sentmerger(cleansents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'In the end, for anarchist historian Daniel |0| Guerin |0|\" Some anarchists are more individualistic than social, some more social than individualistic.',\n",
       " 'From this climate William |0| Godwin |0| developed what many consider the first expression of modern anarchist thought.',\n",
       " 'Godwin |0| was, according to Peter |0| Kropotkin |0|,\" the first to formulate the political and economical conceptions of anarchism, even though he did not give that name to the ideas developed in his work\", while Godwin |0| attached his anarchist ideas to an early Edmund |0| Burke |0|.',\n",
       " \"Proudhon |0|'s followers, the mutualists, opposed Marx |0|'s state socialism, advocating political abstentionism and small property holdings.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerosents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writesents(zerosents, 'en', 'ZERO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerodata = pack_translate(zerosents, 'ZEROX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerodata.to_excel(f'{HOMEPATH}ZEROX_9947sentsT.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B2 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10936\n"
     ]
    }
   ],
   "source": [
    "cleansents = []\n",
    "for i in range(len(data)):\n",
    "    labels = Counter((t[2] for t in data[i]))\n",
    "    if len(labels) == 2 and labels['I-PER'] <= 2:\n",
    "        app = False\n",
    "        for j in range(len(data[i])):\n",
    "            try:\n",
    "                if data[i][j][2] == 'I-PER' and data[i][j][0].endswith(\"'s\"):\n",
    "                    continue\n",
    "                if data[i][j][2] == 'I-PER' and data[i][j + 1][1] == 'VBD':\n",
    "                    data[i][j][0] += ' |0|'\n",
    "                    if j - 1 >= 0:\n",
    "                        if data[i][j - 1][2] == 'I-PER':\n",
    "                            data[i][j - 1][0] += ' |0|'\n",
    "                    app = True\n",
    "                elif data[i][j][2] == 'I-PER':\n",
    "                    data[i][j][0] += ' |0|'\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "        if app:\n",
    "            cleansents.append(data[i])\n",
    "\n",
    "print(len(cleansents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "persres = sentmerger(cleansents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(persres)):\n",
    "    persres[i] = persres[i].replace('|0| |0|', '|0|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(persres)):\n",
    "    if not i % 9:\n",
    "        c = '[woman]'\n",
    "    else:\n",
    "        c = '[man]'\n",
    "    if 'his' in persres[i]:\n",
    "        c = '[man]'\n",
    "    elif ' her' in persres[i]:\n",
    "        c = '[woman]'\n",
    "    persres[i] = persres[i].replace('[???]', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PER recording'''\n",
    "with open(f'{HOMEPATH}perssents.json', 'w', encoding='utf8') as file:\n",
    "    json.dump(persres, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PER reading'''\n",
    "with open(f'{HOMEPATH}perssents.json', encoding='utf8') as file:\n",
    "    persres = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persents = pack_translate(persres, 'ZERORIGHT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joker edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusents = loadsents('ru', 'PER')\n",
    "plsents = loadsents('pl', 'PER')\n",
    "uksents = loadsents('uk', 'PER')\n",
    "besents = loadsents('be', 'PER')\n",
    "bgsents = loadsents('bg', 'PER')\n",
    "slsents = loadsents('sl', 'PER')\n",
    "cssents = loadsents('cs', 'PER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{HOMEPATH}perssents.json') as file:\n",
    "    ensents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persents = list(zip(plsents, besents, uksents, rusents, bgsents, slsents, cssents, ensents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resclean = []\n",
    "for sents in persents:\n",
    "    pol = set(re.findall(r'\\[(?:człowiek.*?|kobiet.*?|mężczyzn.*?)\\]', sents[0].lower()))\n",
    "    if not pol.issubset({'[człowiek]', '[kobieta]', '[mężczyzna]'}) or not pol:\n",
    "        continue\n",
    "    bel = set(re.findall(r'\\[(?:чалавек.*?|жанчын.*?|мужчын.*?)\\]', sents[1].lower()))\n",
    "    if not bel.issubset({'[чалавек]', '[жанчына]', '[мужчына]'}) or not bel:\n",
    "        continue\n",
    "    uk = set(re.findall(r'\\[(?:людин.*?|жінк.*?|чоловік.*?)\\]', sents[2].lower()))\n",
    "    if not uk.issubset({'[людина]', '[жінка]', '[чоловік]'}) or not uk:\n",
    "        continue\n",
    "    rus = set(re.findall(r'\\[(?:человек.*?|женщин.*?|мужчин.*?)\\]', sents[3].lower()))\n",
    "    if not rus.issubset({'[человек]', '[женщина]', '[мужчина]'}) or not rus:\n",
    "        continue\n",
    "    sl = set(re.findall(r'\\[(?:človek.*?|žensk.*?|mož.*?|mošk.*?)\\]', sents[5].lower()))\n",
    "    if not sl.issubset({'[človek]', '[ženska]', '[mož]', '[moški]'}) or not sl:\n",
    "        continue\n",
    "    cs = set(re.findall(r'\\[(?:člověk.*?|žen.*?|muž.*?)\\]', sents[6].lower()))\n",
    "    if not cs.issubset({'[člověk]', '[žena]', '[muž]'}) or not cs:\n",
    "        continue\n",
    "    resclean.append(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(resclean)):\n",
    "    resclean[i] = list(resclean[i])\n",
    "    resclean[i][0] = re.sub(r'(?i)\\[(?:człowiek|mężczyzna)\\]', '[male]', resclean[i][0])\n",
    "    resclean[i][0] = re.sub(r'(?i)\\[kobieta\\]', '[female]', resclean[i][0])\n",
    "    resclean[i][1] = re.sub(r'(?i)\\[(?:чалавек|мужчына)\\]', '[male]', resclean[i][1])\n",
    "    resclean[i][1] = re.sub(r'(?i)\\[жанчына\\]', '[female]', resclean[i][1])\n",
    "    resclean[i][2] = re.sub(r'(?i)\\[(?:людина|чоловік)\\]', '[male]', resclean[i][2])\n",
    "    resclean[i][2] = re.sub(r'(?i)\\[жінка\\]', '[female]', resclean[i][2])\n",
    "    resclean[i][3] = re.sub(r'(?i)\\[(?:человек|мужчина)\\]', '[male]', resclean[i][3])\n",
    "    resclean[i][3] = re.sub(r'(?i)\\[женщина\\]', '[female]', resclean[i][3])\n",
    "    resclean[i][4] = re.sub(r'\\[(?:човек.*?|мъж.*?)\\]', '[male]', resclean[i][4])\n",
    "    resclean[i][4] = re.sub(r'\\[жена.*?\\]', '[female]', resclean[i][4])\n",
    "    resclean[i][5] = re.sub(r'(?i)\\[(?:človek|mož|moški)\\]', '[male]', resclean[i][5])\n",
    "    resclean[i][5] = re.sub(r'(?i)\\[ženska\\]', '[female]', resclean[i][5])\n",
    "    resclean[i][6] = re.sub(r'(?i)\\[(?:člověk|muž)\\]', '[male]', resclean[i][6])\n",
    "    resclean[i][6] = re.sub(r'(?i)\\[žena\\]', '[female]', resclean[i][6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(resclean)):\n",
    "    resclean[i][7] = resclean[i][7].replace('[man]', '[male]')\n",
    "    resclean[i][7] = resclean[i][7].replace('[woman]', '[female]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(resclean, columns=['pl', 'be', 'uk', 'ru', 'bg', 'sl', 'cs', 'en'])\n",
    "df.to_csv(f'{HOMEPATH}PER_sents_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897\n"
     ]
    }
   ],
   "source": [
    "'''LOCATIVE'''\n",
    "cleansents = []\n",
    "for i in range(len(data)):\n",
    "    labels = Counter((t[2] for t in data[i]))\n",
    "    if len(labels) == 2 and labels['I-LOC'] == 1:\n",
    "        for j in range(len(data[i])):\n",
    "            try:\n",
    "                if data[i][j][0] == 'in' and data[i][j + 1][2] == 'I-LOC':\n",
    "                    # data[i][j][0] == ''\n",
    "                    data[i][j + 1][0] += ' |0|'\n",
    "                    cleansents.append(data[i])\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "print(len(cleansents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4350\n"
     ]
    }
   ],
   "source": [
    "'''NOMINATIVE'''\n",
    "# cleansents = []\n",
    "for i in range(len(data)):\n",
    "    labels = Counter((t[2] for t in data[i]))\n",
    "    if len(labels) == 2 and labels['I-LOC'] == 1:\n",
    "        for j in range(len(data[i])):\n",
    "            try:\n",
    "                if (data[i][j][1] in {'VBZ', 'VBP', 'VBN'} and data[i][j + 1][2] == 'I-LOC'):\n",
    "                    data[i][j + 1][0] += ' |0|'\n",
    "                    cleansents.append(data[i])\n",
    "                elif (data[i][j][2] == 'I-LOC' and data[i][j + 1][1]  in {'VBZ', 'VBP', 'VBN'}):\n",
    "                    data[i][j][0] += ' |0|'\n",
    "                    cleansents.append(data[i])\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "print(len(cleansents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locres = sentmerger(cleansents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Only for nominative'''\n",
    "locsents = []\n",
    "for sent in locres:\n",
    "    if 'from the [???]' in sent or 'of the [???]' in sent or 'in [???]' in sent or 'from [???]' in sent or 'of [???]' in sent:\n",
    "        continue\n",
    "    locsents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{HOMEPATH}locwikisentsNOM.txt', 'w', encoding='utf8') as file:\n",
    "    for sent in locsents:\n",
    "        print(sent, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{HOMEPATH}locwikisentsNOM.txt', encoding='utf8') as file:\n",
    "    locsents = [l.rstrip() for l in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "locdata = pd.read_csv(f'{HOMEPATH}1850_nomlocsents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "locdata.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "locdata.to_csv(f'{HOMEPATH}LOC_sents_nom_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Only for locative'''\n",
    "for i in range(len(locsents)):\n",
    "    locsents[i] = locsents[i].replace('[loc]', '[in ???]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The majority of common wet-cured ham available [in ???] supermarkets is of the \" city ham \" variety, [ citation needed ] in which brine is injected into the meat for a very rapid curing suitable for mass market.',\n",
       " 'This dubbing has gathered a cult following [in ???] for that precise reason, although many anime fans consider it highly disrespectful to the original work.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locsents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locdataset = pack_translate(locres, 'ZEROLOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "locdataset = locdataset.apply(lambda x: x.replace('|0| |0|', '|0|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(locdataset, open(f'{HOMEPATH}ZEROLOC_4350sents', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213\n"
     ]
    }
   ],
   "source": [
    "orgsents = []\n",
    "for i in range(len(data)):\n",
    "    labels = Counter((t[2] for t in data[i]))\n",
    "    if len(labels) == 2 and labels['I-ORG'] <= 2:\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j][2] == 'I-ORG':\n",
    "                if j - 1 >= 0:\n",
    "                    if data[i][j - 1][0] == 'is':\n",
    "                        orgsents.append(data[i])\n",
    "                        break\n",
    "                if j + 1 < len(data[i]):\n",
    "                    if data[i][j + 1][1] in {'VBZ', 'VBP', 'VBN'}:\n",
    "                        orgsents.append(data[i])\n",
    "                        break\n",
    "\n",
    "print(len(orgsents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Summerhill |0|  is often cited as an example of anarchism in practice.',\n",
       " ' Studies by the Hadley |0|  Centre |0|  have investigated the relative ( generally warming) effect of albedo change and ( cooling) effect of carbon sequestration on planting forests.',\n",
       " ' Democrats |0|  are still the majority party in both houses of the legislature.',\n",
       " ' Sanmina-SCI |0|  has a large presence in the area.',\n",
       " ' Eight days later, the Council |0|  convenes once more.',\n",
       " ' The General Council |0|  is also responsible for proposing and passing laws.',\n",
       " ' The Supreme |0|  Court |0|  hears civil appeals and may in its discretion hear criminal appeals.',\n",
       " \" The Anchorage |0|  Opera |0|  is currently the state 's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.\",\n",
       " ' While there has been some research on sustainability using GMO crops, at least one hyped and prominent multi-year attempt by Monsanto |0|  Company |0|  has been unsuccessful, though during the same period traditional breeding techniques yielded a more sustainable variety of the same crop.',\n",
       " ' ANSI |0|  accredits standards that are developed by representatives of standards developing organizations, government agencies, consumer groups, companies, and others.',\n",
       " ' UNICEF |0|  estimates that more than 80 percent of females and around 50 percent of males lack access to education centers.',\n",
       " ' The Council |0|  is responsible for carrying out both foreign and domestic policies.',\n",
       " ' RTSH |0|  has a past of being heavily influenced by the ruling party in its reporting, that being left or right winged.',\n",
       " \" One of the primary features of Ōmoto-kyō |0|  is its emphasis on the attainment of utopia during one 's life.\",\n",
       " \" Atari |0|  has also used the game for its other late ' 90s and 2000 's anthology series.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(orgsents)):\n",
    "    sent = ''\n",
    "    for token in orgsents[i]:\n",
    "        if token[2] == 'I-ORG':\n",
    "            # if not sent.endswith('|0|'):\n",
    "            sent += ' ' + token[0] + ' |0| '\n",
    "        else:\n",
    "            if token[0] in '.,!?;:%&*)':\n",
    "                sent += token[0]\n",
    "            else:\n",
    "                sent += f' {token[0]}'\n",
    "    orgsents[i] = sent\n",
    "\n",
    "orgsents[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ressents = []\n",
    "for sent in orgsents:\n",
    "    if 'of the [???]' in sent or 'by [???]' in sent or 'of [???]' in sent or 'in the [???]' in sent or 'in [???]' in sent:\n",
    "        continue\n",
    "    else:\n",
    "        ressents.append(sent)\n",
    "len(ressents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ressents)):\n",
    "    if ' are ' in ressents[i] or ' their ' in ressents[i]:\n",
    "        ressents[i] = ressents[i].replace('[???]', '[companies]')\n",
    "    elif ' party ' in ressents[i]:\n",
    "        ressents[i] = ressents[i].replace('[???]', '[company]')\n",
    "    elif i % 3:\n",
    "        ressents[i] = ressents[i].replace('[???]', '[club]')\n",
    "    else:\n",
    "        ressents[i] = ressents[i].replace('[???]', '[society]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [society] is often cited as an example of anarchism in practice.',\n",
       " ' Studies by the [club] have investigated the relative ( generally warming) effect of albedo change and ( cooling) effect of carbon sequestration on planting forests.',\n",
       " ' [companies] are still the majority party in both houses of the legislature.',\n",
       " ' [society] has a large presence in the area.',\n",
       " ' Eight days later, the [club] convenes once more.',\n",
       " ' The General [club] is also responsible for proposing and passing laws.',\n",
       " ' The [society] hears civil appeals and may in its discretion hear criminal appeals.',\n",
       " \" The [companies] is currently the state 's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.\",\n",
       " ' [companies] accredits standards that are developed by representatives of standards developing organizations, government agencies, consumer groups, companies, and others.',\n",
       " ' [society] estimates that more than 80 percent of females and around 50 percent of males lack access to education centers.',\n",
       " ' The [club] is responsible for carrying out both foreign and domestic policies.',\n",
       " ' [company] has a past of being heavily influenced by the ruling party in its reporting, that being left or right winged.',\n",
       " \" [society] has also used the game for its other late ' 90s and 2000 's anthology series.\",\n",
       " ' To achieve this, [club] has usually engineered its cars with a longitudinally front mounted engine, in an \" overhung \" position, over the front wheels in front of the axle line.',\n",
       " ' Beginning in 2006, [companies] has implemented white LED technology as daytime running lights in their products.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ressents[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgsents = pack_translate(orgsents, 'ZEROORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgsents.to_csv(f'{HOMEPATH}ORG_newsents_{len(orgsents)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation of org sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[???] is often cited as an example of anarchism in practice.',\n",
       " '[???] has a large presence in the area.',\n",
       " 'The [???] is also responsible for proposing and passing laws.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{HOMEPATH}!ORGS.txt', encoding='utf8') as file:\n",
    "    orgres = [s.strip() for s in file.readlines()]\n",
    "\n",
    "orgres[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsents = translating(orgsents, 'pl')\n",
    "rusents = translating(orgsents, 'ru')\n",
    "besents = translating(orgsents, 'be')\n",
    "uksents = translating(orgsents, 'uk')\n",
    "bgsents = translating(orgsents, 'bg')\n",
    "slsents = translating(orgsents, 'sl')\n",
    "cssents = translating(orgsents, 'cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "writesents(plsents, 'pl', 'ORG')\n",
    "writesents(rusents, 'ru', 'ORG')\n",
    "writesents(besents, 'be', 'ORG')\n",
    "writesents(uksents, 'uk', 'ORG')\n",
    "writesents(bgsents, 'bg', 'ORG')\n",
    "writesents(slsents, 'sl', 'ORG')\n",
    "writesents(cssents, 'cs', 'ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [???] є найбільшим у світі розробником стандартів.',\n",
       " ' Другим найбільшим постачальником є \\u200b\\u200b[???].',\n",
       " ' Іммігранти розходяться за своїми політичними поглядами; однак [???] вважається набагато сильніше серед іммігрантів загалом.',\n",
       " ' Сьогодні [???] є провідною міжнародною організацією у світі в своїй галузі, і її стандарти прийняті як національні стандарти її членами.',\n",
       " ' Кожен член [???] обирається терміном на вісім років і може бути переобраний на один або кілька наступних термінів.']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uksents[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{HOMEPATH}ORGS_from_wiki.txt', encoding='utf8') as file:\n",
    "    orgs = [t.rstrip().split('\\t') for t in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs = pd.read_csv(f'{HOMEPATH}ORG_239.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusents = loadsents('ru', 'ORG')\n",
    "plsents = loadsents('pl', 'ORG')\n",
    "uksents = loadsents('uk', 'ORG')\n",
    "besents = loadsents('be', 'ORG')\n",
    "bgsents = loadsents('bg', 'ORG')\n",
    "slsents = loadsents('sl', 'ORG')\n",
    "cssents = loadsents('cs', 'ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(rusents)):\n",
    "    if c >= len(orgs):\n",
    "        c = 0\n",
    "    plsents[i] = plsents[i].replace('[???]', f'|{orgs[c][0]}|')\n",
    "    besents[i] = besents[i].replace('[???]', f'|{orgs[c][1]}|')\n",
    "    uksents[i] = uksents[i].replace('[???]', f'|{orgs[c][2]}|')\n",
    "    rusents[i] = rusents[i].replace('[???]', f'|{orgs[c][3]}|')\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orgsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[???] jest często przytaczany jako przykład anarchizmu w praktyce.', '[???] часта прыводзіцца ў якасці прыкладу анархізму на практыцы.', '[???] часто наводять як приклад анархізму на практиці.', '[???] часто приводят как пример анархизма на практике.', '[???] често се цитира като пример за анархизъм на практика.', '[???] se pogosto navaja kot primer anarhizma v praksi.', '[???] je často uváděn jako příklad anarchismu v praxi.', ' [???] is often cited as an example of anarchism in practice.'), (' Generał [???] jest również odpowiedzialny za proponowanie i uchwalanie ustaw.', ' Генерал [???] таксама адказвае за прапановы і прыняцце законаў.', ' Генерал [???] також відповідає за пропозицію та ухвалення законів.', ' Генерал [???] также отвечает за предложение и принятие законов.', ' Генералът [???] също отговаря за предлагането и приемането на закони.', ' General [???] je pristojen tudi za predlaganje in sprejemanje zakonov.', ' Generál [???] je také zodpovědný za navrhování a přijímání zákonů.', ' The General [???] is also responsible for proposing and passing laws.'), (' [???] jest obecnie jedyną profesjonalną firmą operową w stanie, chociaż istnieje również kilka organizacji ochotniczych i półprofesjonalnych w stanie.', \" У цяперашні час [???] з'яўляецца адзінай прафесійнай опернай трупай у штаце, хоць у штаце таксама існуе некалькі валанцёрскіх і паўпрафесійных арганізацый.\", ' Наразі [???] є єдиною професійною оперною трупою штату, хоча в штаті також є кілька волонтерських і напівпрофесійних організацій.', ' [???] в настоящее время является единственной профессиональной оперной труппой в штате, хотя в штате также есть несколько волонтерских и полупрофессиональных организаций.', ' [???] в момента е единствената професионална оперна трупа в щата, въпреки че в щата също има няколко доброволчески и полупрофесионални организации.', ' [???] je trenutno edina profesionalna operna družba v državi, čeprav je v državi tudi več prostovoljnih in polprofesionalnih organizacij.', ' [???] je v současné době jedinou profesionální operní společností ve státě, i když ve státě působí také několik dobrovolníků a poloprofesionálních organizací.', \" The [???] is currently the state 's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.\"), (' [???] odpowiada za prowadzenie zarówno polityki zagranicznej, jak i krajowej.', ' [???] адказвае за правядзенне як знешняй, так і ўнутранай палітыкі.', ' [???] відповідає за проведення як зовнішньої, так і внутрішньої політики.', ' [???] отвечает за проведение как внешней, так и внутренней политики.', ' [???] отговаря за провеждането както на външната, така и на вътрешната политика.', ' [???] je odgovoren za izvajanje zunanje in notranje politike.', ' [???] je odpovědná za provádění zahraniční i domácí politiky.', ' The [???] is responsible for carrying out both foreign and domestic policies.')]\n"
     ]
    }
   ],
   "source": [
    "orgdata = list(zip(plsents, besents, uksents, rusents, bgsents, slsents, cssents, orgsents))\n",
    "print(orgdata[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(orgdata)):\n",
    "    c = randint(0, len(orgs) - 1)\n",
    "    orgdata[i] = list(orgdata[i])\n",
    "    for j in range(7):\n",
    "        orgdata[i][j] = orgdata[i][j].replace('[???]', f'|{orgs.iloc[c][j]}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['|Amnesty International| jest często przytaczany jako przykład anarchizmu w praktyce.', '|Міжнародная амністыя| часта прыводзіцца ў якасці прыкладу анархізму на практыцы.', '|Amnesty International| часто наводять як приклад анархізму на практиці.', '|Amnesty International| часто приводят как пример анархизма на практике.', '|Амнести Интернешънъл| често се цитира като пример за анархизъм на практика.', '|Amnesty International| se pogosto navaja kot primer anarhizma v praksi.', '|Amnesty International| je často uváděn jako příklad anarchismu v praxi.'], [' Generał |Greenpeace| jest również odpowiedzialny za proponowanie i uchwalanie ustaw.', ' Генерал |Greenpeace| таксама адказвае за прапановы і прыняцце законаў.', ' Генерал |Грінпіс| також відповідає за пропозицію та ухвалення законів.', ' Генерал |Гринпис| также отвечает за предложение и принятие законов.', ' Генералът |Грийнпийс| също отговаря за предлагането и приемането на закони.', ' General |Greenpeace| je pristojen tudi za predlaganje in sprejemanje zakonov.', ' Generál |Greenpeace| je také zodpovědný za navrhování a přijímání zákonů.'], [' |Unia Narodów Południowoamerykańskich| jest obecnie jedyną profesjonalną firmą operową w stanie, chociaż istnieje również kilka organizacji ochotniczych i półprofesjonalnych w stanie.', \" У цяперашні час |UNASUR| з'яўляецца адзінай прафесійнай опернай трупай у штаце, хоць у штаце таксама існуе некалькі валанцёрскіх і паўпрафесійных арганізацый.\", ' Наразі |Союз південноамериканських націй| є єдиною професійною оперною трупою штату, хоча в штаті також є кілька волонтерських і напівпрофесійних організацій.', ' |Союз южноамериканских наций| в настоящее время является единственной профессиональной оперной труппой в штате, хотя в штате также есть несколько волонтерских и полупрофессиональных организаций.', ' |Съюз на южноамериканските нации| в момента е единствената професионална оперна трупа в щата, въпреки че в щата също има няколко доброволчески и полупрофесионални организации.', ' |Unija južnoameriških držav| je trenutno edina profesionalna operna družba v državi, čeprav je v državi tudi več prostovoljnih in polprofesionalnih organizacij.', ' |Unie jihoamerických národů| je v současné době jedinou profesionální operní společností ve státě, i když ve státě působí také několik dobrovolníků a poloprofesionálních organizací.'], [' |Massachusetts Institute of Technology| odpowiada za prowadzenie zarówno polityki zagranicznej, jak i krajowej.', ' |Масачусецкі тэхналагічны інстытут| адказвае за правядзенне як знешняй, так і ўнутранай палітыкі.', ' |Массачусетський технологічний інститут| відповідає за проведення як зовнішньої, так і внутрішньої політики.', ' |Массачусетский технологический институт| отвечает за проведение как внешней, так и внутренней политики.', ' |Масачузетски технологичен институт| отговаря за провеждането както на външната, така и на вътрешната политика.', ' |Tehnološki inštitut Massachusettsa| je odgovoren za izvajanje zunanje in notranje politike.', ' |Massachusettský technologický institut| je odpovědná za provádění zahraniční i domácí politiky.']]\n"
     ]
    }
   ],
   "source": [
    "print(orgdata[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orgdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgtable = pd.DataFrame(orgdata, columns=['pl', 'be', 'uk', 'ru', 'bg', 'sl', 'cs', 'en'])\n",
    "orgtable.to_csv(f'{HOMEPATH}ORG_sents_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = pd.read_csv(f'{HOMEPATH}LOC_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pl</th>\n",
       "      <th>be</th>\n",
       "      <th>uk</th>\n",
       "      <th>ru</th>\n",
       "      <th>bg</th>\n",
       "      <th>sl</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Індыя</td>\n",
       "      <td>Індія</td>\n",
       "      <td>Индия</td>\n",
       "      <td>Индия</td>\n",
       "      <td>Indija</td>\n",
       "      <td>Indie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hiszpania</td>\n",
       "      <td>Іспанія</td>\n",
       "      <td>Іспанія</td>\n",
       "      <td>Испания</td>\n",
       "      <td>Испания</td>\n",
       "      <td>Španija</td>\n",
       "      <td>Španělsko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Włochy</td>\n",
       "      <td>Італія</td>\n",
       "      <td>Італія</td>\n",
       "      <td>Италия</td>\n",
       "      <td>Италия</td>\n",
       "      <td>Italija</td>\n",
       "      <td>Itálie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nur-Sułtan</td>\n",
       "      <td>Акмала</td>\n",
       "      <td>Нур-Султан</td>\n",
       "      <td>Нур-Султан</td>\n",
       "      <td>Нур Султан</td>\n",
       "      <td>Nursultan</td>\n",
       "      <td>Nur-Sultan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aleksandria</td>\n",
       "      <td>Аляксандрыя</td>\n",
       "      <td>Александрія</td>\n",
       "      <td>Александрия</td>\n",
       "      <td>Александрия</td>\n",
       "      <td>Aleksandrija</td>\n",
       "      <td>Alexandrie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           pl           be           uk           ru  \\\n",
       "0           0        Indie        Індыя        Індія        Индия   \n",
       "1           1    Hiszpania      Іспанія      Іспанія      Испания   \n",
       "2           2       Włochy       Італія       Італія       Италия   \n",
       "3           3   Nur-Sułtan       Акмала   Нур-Султан   Нур-Султан   \n",
       "4           4  Aleksandria  Аляксандрыя  Александрія  Александрия   \n",
       "\n",
       "            bg            sl          cs  \n",
       "0        Индия        Indija       Indie  \n",
       "1      Испания       Španija   Španělsko  \n",
       "2       Италия       Italija      Itálie  \n",
       "3   Нур Султан     Nursultan  Nur-Sultan  \n",
       "4  Александрия  Aleksandrija  Alexandrie  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in locs.iterrows():\n",
    "    if 'Горад' in locs.loc[i, 'be']:\n",
    "        locs.loc[i, 'be'] = locs.loc[i, 'be'].replace('Горад ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in locs.columns:\n",
    "    locs[column] = locs[column].apply(lambda x: re.sub(r' \\(.+?\\)', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>be</th>\n",
       "      <th>uk</th>\n",
       "      <th>ru</th>\n",
       "      <th>bg</th>\n",
       "      <th>sl</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Opole</td>\n",
       "      <td>Опельн</td>\n",
       "      <td>Ополе</td>\n",
       "      <td>Ополе</td>\n",
       "      <td>Ополе</td>\n",
       "      <td>Opole</td>\n",
       "      <td>Opolí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>Брысталь</td>\n",
       "      <td>Бристоль</td>\n",
       "      <td>Бристоль</td>\n",
       "      <td>Бристъл</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Bristol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Uetersen</td>\n",
       "      <td>Uetersen</td>\n",
       "      <td>Ютерзен</td>\n",
       "      <td>Итерзен</td>\n",
       "      <td>Ютерзен</td>\n",
       "      <td>Uetersen</td>\n",
       "      <td>Uetersen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>Hiszpania</td>\n",
       "      <td>Каралеўства Іспанія</td>\n",
       "      <td>Іспанія</td>\n",
       "      <td>Испания</td>\n",
       "      <td>Испания</td>\n",
       "      <td>Španija</td>\n",
       "      <td>Španělsko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>Słowacja</td>\n",
       "      <td>Славацкая рэспубліка</td>\n",
       "      <td>Словаччина</td>\n",
       "      <td>Словакия</td>\n",
       "      <td>Словакия</td>\n",
       "      <td>Slovaška</td>\n",
       "      <td>Slovensko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>Wagharszapat</td>\n",
       "      <td>Вагаршапат</td>\n",
       "      <td>Вагаршапат</td>\n",
       "      <td>Вагаршапат</td>\n",
       "      <td>Вагаршапат</td>\n",
       "      <td>Ečmiadzin</td>\n",
       "      <td>Vagharšapat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Korea Północna</td>\n",
       "      <td>КНДР</td>\n",
       "      <td>Північна Корея</td>\n",
       "      <td>Корейская Народно-Демократическая Республика</td>\n",
       "      <td>Северна Корея</td>\n",
       "      <td>Severna Koreja</td>\n",
       "      <td>Severní Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Nukuʻalofa</td>\n",
       "      <td>Нукуалофа</td>\n",
       "      <td>Нукуалофа</td>\n",
       "      <td>Нукуалофа</td>\n",
       "      <td>Нукуалофа</td>\n",
       "      <td>Nukuʻalofa</td>\n",
       "      <td>Nuku'alofa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Bissau</td>\n",
       "      <td>Бісау</td>\n",
       "      <td>Бісау</td>\n",
       "      <td>Бисау</td>\n",
       "      <td>Бисау</td>\n",
       "      <td>Bissau</td>\n",
       "      <td>Bissau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>Bamako</td>\n",
       "      <td>Бамака</td>\n",
       "      <td>Бамако</td>\n",
       "      <td>Бамако</td>\n",
       "      <td>Бамако</td>\n",
       "      <td>Bamako</td>\n",
       "      <td>Bamako</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pl                    be              uk  \\\n",
       "2001           Opole                Опельн           Ополе   \n",
       "1889         Bristol              Брысталь        Бристоль   \n",
       "476         Uetersen              Uetersen         Ютерзен   \n",
       "1656       Hiszpania   Каралеўства Іспанія         Іспанія   \n",
       "1884        Słowacja  Славацкая рэспубліка      Словаччина   \n",
       "1535    Wagharszapat            Вагаршапат      Вагаршапат   \n",
       "30    Korea Północna                  КНДР  Північна Корея   \n",
       "233       Nukuʻalofa             Нукуалофа       Нукуалофа   \n",
       "121           Bissau                 Бісау           Бісау   \n",
       "1347          Bamako                Бамака          Бамако   \n",
       "\n",
       "                                                ru             bg  \\\n",
       "2001                                         Ополе          Ополе   \n",
       "1889                                      Бристоль        Бристъл   \n",
       "476                                        Итерзен        Ютерзен   \n",
       "1656                                       Испания        Испания   \n",
       "1884                                      Словакия       Словакия   \n",
       "1535                                    Вагаршапат     Вагаршапат   \n",
       "30    Корейская Народно-Демократическая Республика  Северна Корея   \n",
       "233                                      Нукуалофа      Нукуалофа   \n",
       "121                                          Бисау          Бисау   \n",
       "1347                                        Бамако         Бамако   \n",
       "\n",
       "                  sl             cs  \n",
       "2001           Opole          Opolí  \n",
       "1889         Bristol        Bristol  \n",
       "476         Uetersen       Uetersen  \n",
       "1656         Španija      Španělsko  \n",
       "1884        Slovaška      Slovensko  \n",
       "1535       Ečmiadzin    Vagharšapat  \n",
       "30    Severna Koreja  Severní Korea  \n",
       "233       Nukuʻalofa     Nuku'alofa  \n",
       "121           Bissau         Bissau  \n",
       "1347          Bamako         Bamako  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pl           Ho Chi Minh\n",
       "be                Сайгон\n",
       "uk               Хошимін\n",
       "ru               Хошимин\n",
       "bg               Хошимин\n",
       "sl              Hošiminh\n",
       "cs    Ho Či Minovo Město\n",
       "Name: 262, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs.loc[262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs.drop_duplicates(subset=['ru'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1263"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(locs, open(f'{HOMEPATH}1263_locs', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs.to_csv(f'{HOMEPATH}LOC_1263.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eb9e1cf2af2cf6251f1c932a803c6b2f25b1e2cfa2de873853bae064510a498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
